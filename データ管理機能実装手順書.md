# ãƒ‡ãƒ¼ã‚¿ç®¡ç†æ©Ÿèƒ½ è©³ç´°å®Ÿè£…æ‰‹é †æ›¸
## ã™ãã™ããƒŸãƒ³ãƒˆã¡ã‚ƒã‚“ - ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ»ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

---

## ğŸ“‹ æ¦‚è¦
ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã€çµ¦æ°´å±¥æ­´ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ãƒ»ç®¡ç†ãƒ»å‰Šé™¤æ©Ÿèƒ½ã®è©³ç´°å®Ÿè£…æ‰‹é †æ›¸

## ğŸ¯ å®Ÿè£…ç›®æ¨™
- CSVå½¢å¼ã§ã®ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜
- JSONå½¢å¼ã§ã®çµ¦æ°´å±¥æ­´ä¿å­˜
- JPEGå½¢å¼ã§ã®ç”»åƒä¿å­˜
- 90æ—¥é–“ã®è‡ªå‹•å‰Šé™¤æ©Ÿèƒ½
- USBã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸ã®å®‰å…¨ãªä¿å­˜
- ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯

---

## ğŸ› ï¸ å¿…è¦ãªç’°å¢ƒ

### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢
- USBã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ (16GBä»¥ä¸Š)
- Raspberry Pi 5

### ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢
- Python 3.11.x
- pandas (ãƒ‡ãƒ¼ã‚¿å‡¦ç†)
- Pillow (ç”»åƒå‡¦ç†)
- pathlib (ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†)

---

## ğŸ”§ å®Ÿè£…æ‰‹é †

### Step 1: ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹å®Ÿè£…

#### 1.1 åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹
```python
# src/data/data_manager.py
import os
import json
import csv
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional
import pandas as pd
from PIL import Image
import shutil

class DataManager:
    """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_path: str = "/mnt/usb-storage"):
        self.base_path = Path(base_path)
        self.logger = logging.getLogger("data_manager")
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜æœŸé–“ï¼ˆæ—¥ï¼‰
        self.retention_days = 90
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        self.directories = {
            'sensor_data': self.base_path / 'sensor_data',
            'watering_history': self.base_path / 'watering_history',
            'images': self.base_path / 'images',
            'logs': self.base_path / 'logs',
            'backup': self.base_path / 'backup'
        }
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self._create_directories()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«
        self.metadata_file = self.base_path / 'metadata.json'
        self._load_metadata()
    
    def _create_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        for dir_name, dir_path in self.directories.items():
            dir_path.mkdir(parents=True, exist_ok=True)
            self.logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {dir_path}")
    
    def _load_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if self.metadata_file.exists():
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
            else:
                self.metadata = {
                    'created_at': datetime.now().isoformat(),
                    'last_cleanup': None,
                    'file_counts': {},
                    'total_size_bytes': 0
                }
                self._save_metadata()
        except Exception as e:
            self.logger.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            self.metadata = {}
    
    def _save_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def save_sensor_data(self, data: Dict[str, Any]) -> bool:
        """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã§ä¿å­˜"""
        try:
            timestamp = datetime.now()
            filename = f"sensor_data_{timestamp.strftime('%Y%m%d')}.csv"
            filepath = self.directories['sensor_data'] / filename
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            file_exists = filepath.exists()
            
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            csv_data = {
                'timestamp': timestamp.isoformat(),
                'temperature': data.get('temperature_humidity', {}).get('temperature', ''),
                'humidity': data.get('temperature_humidity', {}).get('humidity', ''),
                'soil_moisture_raw': data.get('soil_moisture', {}).get('raw_value', ''),
                'soil_moisture_filtered': data.get('soil_moisture', {}).get('filtered_value', ''),
                'soil_moisture_percentage': data.get('soil_moisture', {}).get('moisture_percentage', ''),
                'water_level': data.get('water_level', {}).get('is_water_available', ''),
                'water_level_raw': data.get('water_level', {}).get('raw_state', '')
            }
            
            # CSVæ›¸ãè¾¼ã¿
            with open(filepath, 'a', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=csv_data.keys())
                if not file_exists:
                    writer.writeheader()
                writer.writerow(csv_data)
            
            self._update_file_count('sensor_data')
            self.logger.debug(f"ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def save_watering_record(self, record: Dict[str, Any]) -> bool:
        """çµ¦æ°´è¨˜éŒ²ã‚’JSONå½¢å¼ã§ä¿å­˜"""
        try:
            timestamp = datetime.now()
            filename = f"watering_{timestamp.strftime('%Y%m%d')}.json"
            filepath = self.directories['watering_history'] / filename
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            existing_data = []
            if filepath.exists():
                with open(filepath, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            
            # æ–°ã—ã„è¨˜éŒ²è¿½åŠ 
            record['saved_at'] = timestamp.isoformat()
            existing_data.append(record)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
            
            self._update_file_count('watering_history')
            self.logger.debug(f"çµ¦æ°´è¨˜éŒ²ä¿å­˜: {filepath}")
            return True
            
        except Exception as e:
            self.logger.error(f"çµ¦æ°´è¨˜éŒ²ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def save_image(self, image_data: bytes, metadata: Dict[str, Any] = None) -> Optional[str]:
        """ç”»åƒã‚’JPEGå½¢å¼ã§ä¿å­˜"""
        try:
            timestamp = datetime.now()
            filename = f"{timestamp.strftime('%Y%m%d_%H%M%S')}.jpg"
            filepath = self.directories['images'] / filename
            
            # ç”»åƒä¿å­˜
            with open(filepath, 'wb') as f:
                f.write(image_data)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if metadata:
                metadata_file = filepath.with_suffix('.json')
                metadata['filename'] = filename
                metadata['saved_at'] = timestamp.isoformat()
                metadata['file_size'] = len(image_data)
                
                with open(metadata_file, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            self._update_file_count('images')
            self.logger.debug(f"ç”»åƒä¿å­˜: {filepath}")
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"ç”»åƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def get_sensor_data(self, start_date: datetime = None, end_date: datetime = None) -> List[Dict[str, Any]]:
        """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            data = []
            
            # æ—¥ä»˜ç¯„å›²ã®è¨­å®š
            if not start_date:
                start_date = datetime.now() - timedelta(days=7)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ7æ—¥é–“
            if not end_date:
                end_date = datetime.now()
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            for file_path in self.directories['sensor_data'].glob('sensor_data_*.csv'):
                try:
                    df = pd.read_csv(file_path)
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
                    
                    # æ—¥ä»˜ç¯„å›²ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    filtered_df = df[(df['timestamp'] >= start_date) & (df['timestamp'] <= end_date)]
                    
                    for _, row in filtered_df.iterrows():
                        data.append(row.to_dict())
                        
                except Exception as e:
                    self.logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {str(e)}")
            
            return sorted(data, key=lambda x: x['timestamp'])
            
        except Exception as e:
            self.logger.error(f"ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_watering_history(self, days: int = 30) -> List[Dict[str, Any]]:
        """çµ¦æ°´å±¥æ­´ã‚’å–å¾—"""
        try:
            history = []
            start_date = datetime.now() - timedelta(days=days)
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            for file_path in self.directories['watering_history'].glob('watering_*.json'):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        file_data = json.load(f)
                    
                    for record in file_data:
                        record_date = datetime.fromisoformat(record['timestamp'])
                        if record_date >= start_date:
                            history.append(record)
                            
                except Exception as e:
                    self.logger.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {str(e)}")
            
            return sorted(history, key=lambda x: x['timestamp'])
            
        except Exception as e:
            self.logger.error(f"çµ¦æ°´å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def get_images(self, days: int = 30) -> List[Dict[str, Any]]:
        """ç”»åƒä¸€è¦§ã‚’å–å¾—"""
        try:
            images = []
            start_date = datetime.now() - timedelta(days=days)
            
            for file_path in self.directories['images'].glob('*.jpg'):
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆæ—¥æ™‚ã‚’å–å¾—
                    file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                    
                    if file_time >= start_date:
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
                        metadata_file = file_path.with_suffix('.json')
                        metadata = {}
                        if metadata_file.exists():
                            with open(metadata_file, 'r', encoding='utf-8') as f:
                                metadata = json.load(f)
                        
                        images.append({
                            'filename': file_path.name,
                            'filepath': str(file_path),
                            'timestamp': file_time.isoformat(),
                            'file_size': file_path.stat().st_size,
                            'metadata': metadata
                        })
                        
                except Exception as e:
                    self.logger.error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {file_path}: {str(e)}")
            
            return sorted(images, key=lambda x: x['timestamp'])
            
        except Exception as e:
            self.logger.error(f"ç”»åƒä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def cleanup_old_data(self) -> Dict[str, int]:
        """å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
        try:
            cutoff_date = datetime.now() - timedelta(days=self.retention_days)
            deleted_counts = {
                'sensor_data': 0,
                'watering_history': 0,
                'images': 0
            }
            
            # ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
            for file_path in self.directories['sensor_data'].glob('sensor_data_*.csv'):
                if datetime.fromtimestamp(file_path.stat().st_mtime) < cutoff_date:
                    file_path.unlink()
                    deleted_counts['sensor_data'] += 1
            
            # çµ¦æ°´å±¥æ­´å‰Šé™¤
            for file_path in self.directories['watering_history'].glob('watering_*.json'):
                if datetime.fromtimestamp(file_path.stat().st_mtime) < cutoff_date:
                    file_path.unlink()
                    deleted_counts['watering_history'] += 1
            
            # ç”»åƒå‰Šé™¤
            for file_path in self.directories['images'].glob('*.jpg'):
                if datetime.fromtimestamp(file_path.stat().st_mtime) < cutoff_date:
                    file_path.unlink()
                    # å¯¾å¿œã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
                    metadata_file = file_path.with_suffix('.json')
                    if metadata_file.exists():
                        metadata_file.unlink()
                    deleted_counts['images'] += 1
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            self.metadata['last_cleanup'] = datetime.now().isoformat()
            self._save_metadata()
            
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {deleted_counts}")
            return deleted_counts
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}
    
    def get_storage_info(self) -> Dict[str, Any]:
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±ã‚’å–å¾—"""
        try:
            total_size = 0
            file_counts = {}
            
            for dir_name, dir_path in self.directories.items():
                if dir_path.exists():
                    dir_size = sum(f.stat().st_size for f in dir_path.rglob('*') if f.is_file())
                    dir_count = len(list(dir_path.rglob('*')))
                    
                    total_size += dir_size
                    file_counts[dir_name] = {
                        'count': dir_count,
                        'size_bytes': dir_size,
                        'size_mb': round(dir_size / (1024 * 1024), 2)
                    }
            
            return {
                'total_size_bytes': total_size,
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'total_size_gb': round(total_size / (1024 * 1024 * 1024), 2),
                'file_counts': file_counts,
                'retention_days': self.retention_days,
                'last_cleanup': self.metadata.get('last_cleanup'),
                'base_path': str(self.base_path)
            }
            
        except Exception as e:
            self.logger.error(f"ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}
    
    def backup_data(self, backup_name: str = None) -> Optional[str]:
        """ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
        try:
            if not backup_name:
                backup_name = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            backup_path = self.directories['backup'] / backup_name
            backup_path.mkdir(exist_ok=True)
            
            # å„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚³ãƒ”ãƒ¼
            for dir_name, dir_path in self.directories.items():
                if dir_name != 'backup' and dir_path.exists():
                    dest_path = backup_path / dir_name
                    shutil.copytree(dir_path, dest_path)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã‚³ãƒ”ãƒ¼
            if self.metadata_file.exists():
                shutil.copy2(self.metadata_file, backup_path / 'metadata.json')
            
            self.logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: {backup_path}")
            return str(backup_path)
            
        except Exception as e:
            self.logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _update_file_count(self, data_type: str):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚«ã‚¦ãƒ³ãƒˆã‚’æ›´æ–°"""
        try:
            if 'file_counts' not in self.metadata:
                self.metadata['file_counts'] = {}
            
            if data_type not in self.metadata['file_counts']:
                self.metadata['file_counts'][data_type] = 0
            
            self.metadata['file_counts'][data_type] += 1
            self._save_metadata()
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚«ã‚¦ãƒ³ãƒˆæ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
```

### Step 2: ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼

#### 2.1 çµ±åˆãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
```python
# src/data/data_manager_service.py
import threading
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, Any
from .data_manager import DataManager

class DataManagerService:
    """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.data_manager = DataManager()
        self.logger = logging.getLogger("data_manager_service")
        
        self.running = False
        self.save_thread = None
        self.cleanup_thread = None
        
        # ä¿å­˜é–“éš”ï¼ˆç§’ï¼‰
        self.save_interval = 300  # 5åˆ†é–“éš”
        self.cleanup_interval = 86400  # 24æ™‚é–“é–“éš”
        
    def start_service(self):
        """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹é–‹å§‹"""
        if self.running:
            self.logger.warning("ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™")
            return
        
        self.running = True
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¹ãƒ¬ãƒƒãƒ‰
        self.save_thread = threading.Thread(
            target=self._periodic_save,
            daemon=True
        )
        self.save_thread.start()
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ãƒ¬ãƒƒãƒ‰
        self.cleanup_thread = threading.Thread(
            target=self._periodic_cleanup,
            daemon=True
        )
        self.cleanup_thread.start()
        
        self.logger.info("ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹é–‹å§‹")
    
    def stop_service(self):
        """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢"""
        self.running = False
        if self.save_thread:
            self.save_thread.join(timeout=5)
        if self.cleanup_thread:
            self.cleanup_thread.join(timeout=5)
        self.logger.info("ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢")
    
    def _periodic_save(self):
        """å®šæœŸçš„ãªãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        while self.running:
            try:
                # ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã¯å„ã‚»ãƒ³ã‚µãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã§å®Ÿè¡Œ
                # ã“ã“ã§ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã®ã¿
                time.sleep(self.save_interval)
            except Exception as e:
                self.logger.error(f"å®šæœŸä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
                time.sleep(60)
    
    def _periodic_cleanup(self):
        """å®šæœŸçš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        while self.running:
            try:
                time.sleep(self.cleanup_interval)
                
                if self.running:
                    deleted_counts = self.data_manager.cleanup_old_data()
                    self.logger.info(f"å®šæœŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {deleted_counts}")
                    
            except Exception as e:
                self.logger.error(f"å®šæœŸã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}")
                time.sleep(3600)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1æ™‚é–“å¾…æ©Ÿ
    
    def save_sensor_data(self, data: Dict[str, Any]) -> bool:
        """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        return self.data_manager.save_sensor_data(data)
    
    def save_watering_record(self, record: Dict[str, Any]) -> bool:
        """çµ¦æ°´è¨˜éŒ²ä¿å­˜"""
        return self.data_manager.save_watering_record(record)
    
    def save_image(self, image_data: bytes, metadata: Dict[str, Any] = None) -> Optional[str]:
        """ç”»åƒä¿å­˜"""
        return self.data_manager.save_image(image_data, metadata)
    
    def get_sensor_data(self, days: int = 7) -> List[Dict[str, Any]]:
        """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        return self.data_manager.get_sensor_data(start_date, end_date)
    
    def get_watering_history(self, days: int = 30) -> List[Dict[str, Any]]:
        """çµ¦æ°´å±¥æ­´å–å¾—"""
        return self.data_manager.get_watering_history(days)
    
    def get_images(self, days: int = 30) -> List[Dict[str, Any]]:
        """ç”»åƒä¸€è¦§å–å¾—"""
        return self.data_manager.get_images(days)
    
    def get_storage_info(self) -> Dict[str, Any]:
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±å–å¾—"""
        return self.data_manager.get_storage_info()
    
    def create_backup(self, backup_name: str = None) -> Optional[str]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        return self.data_manager.backup_data(backup_name)
    
    def manual_cleanup(self) -> Dict[str, int]:
        """æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        return self.data_manager.cleanup_old_data()
```

### Step 3: ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ

#### 3.1 æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ
```python
# src/sensors/sensor_manager.py ã«è¿½åŠ 
class SensorManager:
    def __init__(self, data_manager_service=None):
        # æ—¢å­˜ã®åˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰...
        self.data_manager_service = data_manager_service
    
    def _monitor_temperature_humidity(self):
        """æ¸©æ¹¿åº¦ã‚»ãƒ³ã‚µãƒ¼ç›£è¦–ï¼ˆãƒ‡ãƒ¼ã‚¿ä¿å­˜è¿½åŠ ï¼‰"""
        while self.running:
            try:
                data = self.sensors['temperature_humidity'].read_data()
                if 'error' not in data:
                    self.data_cache['temperature_humidity'] = data
                    
                    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    if self.data_manager_service:
                        self.data_manager_service.save_sensor_data(self.data_cache)
                    
                    self.logger.debug(f"æ¸©æ¹¿åº¦ãƒ‡ãƒ¼ã‚¿æ›´æ–°: {data}")
                else:
                    self.logger.error(f"æ¸©æ¹¿åº¦ã‚»ãƒ³ã‚µãƒ¼ã‚¨ãƒ©ãƒ¼: {data['error']}")
                
                time.sleep(1800)  # 30åˆ†å¾…æ©Ÿ
                
            except Exception as e:
                self.logger.error(f"æ¸©æ¹¿åº¦ç›£è¦–ã‚¨ãƒ©ãƒ¼: {str(e)}")
                time.sleep(60)

# src/watering/watering_controller.py ã«è¿½åŠ 
class WateringController:
    def __init__(self, data_manager_service=None):
        # æ—¢å­˜ã®åˆæœŸåŒ–ã‚³ãƒ¼ãƒ‰...
        self.data_manager_service = data_manager_service
    
    def start_watering(self, soil_moisture: float, water_available: bool) -> Dict[str, Any]:
        # æ—¢å­˜ã®çµ¦æ°´å‡¦ç†...
        
        # å±¥æ­´è¨˜éŒ²
        watering_record = {
            'timestamp': self.last_watering_time.isoformat(),
            'soil_moisture': soil_moisture,
            'duration_seconds': self.watering_duration_seconds,
            'water_amount_ml': self.water_amount_ml,
            'consecutive_count': self.consecutive_watering_count,
            'success': True
        }
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        if self.data_manager_service:
            self.data_manager_service.save_watering_record(watering_record)
        
        # æ—¢å­˜ã®å‡¦ç†ç¶šè¡Œ...
```

### Step 4: APIå®Ÿè£…

#### 4.1 ãƒ‡ãƒ¼ã‚¿ç®¡ç†API
```python
# src/api/data_api.py
from flask import Blueprint, jsonify, request
import logging

data_bp = Blueprint('data', __name__)
logger = logging.getLogger("data_api")

@sensor_bp.route('/data/sensor', methods=['GET'])
def get_sensor_data():
    """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    try:
        from ..app import data_manager_service
        if not data_manager_service:
            return jsonify({'error': 'ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500
        
        days = request.args.get('days', 7, type=int)
        data = data_manager_service.get_sensor_data(days)
        return jsonify({'data': data})
    except Exception as e:
        logger.error(f"ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({'error': str(e)}), 500

@sensor_bp.route('/data/watering', methods=['GET'])
def get_watering_history():
    """çµ¦æ°´å±¥æ­´å–å¾—"""
    try:
        from ..app import data_manager_service
        if not data_manager_service:
            return jsonify({'error': 'ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500
        
        days = request.args.get('days', 30, type=int)
        history = data_manager_service.get_watering_history(days)
        return jsonify({'history': history})
    except Exception as e:
        logger.error(f"çµ¦æ°´å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({'error': str(e)}), 500

@sensor_bp.route('/data/images', methods=['GET'])
def get_images():
    """ç”»åƒä¸€è¦§å–å¾—"""
    try:
        from ..app import data_manager_service
        if not data_manager_service:
            return jsonify({'error': 'ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500
        
        days = request.args.get('days', 30, type=int)
        images = data_manager_service.get_images(days)
        return jsonify({'images': images})
    except Exception as e:
        logger.error(f"ç”»åƒä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({'error': str(e)}), 500

@sensor_bp.route('/data/storage', methods=['GET'])
def get_storage_info():
    """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±å–å¾—"""
    try:
        from ..app import data_manager_service
        if not data_manager_service:
            return jsonify({'error': 'ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500
        
        info = data_manager_service.get_storage_info()
        return jsonify(info)
    except Exception as e:
        logger.error(f"ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({'error': str(e)}), 500

@sensor_bp.route('/data/cleanup', methods=['POST'])
def manual_cleanup():
    """æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    try:
        from ..app import data_manager_service
        if not data_manager_service:
            return jsonify({'error': 'ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500
        
        deleted_counts = data_manager_service.manual_cleanup()
        return jsonify({'success': True, 'deleted_counts': deleted_counts})
    except Exception as e:
        logger.error(f"æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({'error': str(e)}), 500

@sensor_bp.route('/data/backup', methods=['POST'])
def create_backup():
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
    try:
        from ..app import data_manager_service
        if not data_manager_service:
            return jsonify({'error': 'ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 500
        
        backup_name = request.json.get('backup_name') if request.json else None
        backup_path = data_manager_service.create_backup(backup_name)
        
        if backup_path:
            return jsonify({'success': True, 'backup_path': backup_path})
        else:
            return jsonify({'success': False, 'error': 'ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå¤±æ•—'})
    except Exception as e:
        logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({'error': str(e)}), 500
```

### Step 5: ãƒ†ã‚¹ãƒˆå®Ÿè£…

#### 5.1 ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ†ã‚¹ãƒˆ
```python
# test_data_management.py
import time
import logging
from src.data.data_manager_service import DataManagerService

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def test_data_management():
    """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
    data_service = DataManagerService()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    test_sensor_data = {
        'temperature_humidity': {'temperature': 25.5, 'humidity': 60.0},
        'soil_moisture': {'moisture_percentage': 45.2, 'raw_value': 462},
        'water_level': {'is_water_available': True}
    }
    
    test_watering_record = {
        'timestamp': '2025-01-15T10:30:00',
        'soil_moisture': 45.2,
        'duration_seconds': 5,
        'water_amount_ml': 100,
        'success': True
    }
    
    # ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“Š ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆ")
    result = data_service.save_sensor_data(test_sensor_data)
    print(f"ä¿å­˜çµæœ: {result}")
    
    # çµ¦æ°´è¨˜éŒ²ä¿å­˜ãƒ†ã‚¹ãƒˆ
    print("\nğŸ’§ çµ¦æ°´è¨˜éŒ²ä¿å­˜ãƒ†ã‚¹ãƒˆ")
    result = data_service.save_watering_record(test_watering_record)
    print(f"ä¿å­˜çµæœ: {result}")
    
    # ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ")
    sensor_data = data_service.get_sensor_data(7)
    print(f"ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(sensor_data)}")
    
    watering_history = data_service.get_watering_history(30)
    print(f"çµ¦æ°´å±¥æ­´ä»¶æ•°: {len(watering_history)}")
    
    images = data_service.get_images(30)
    print(f"ç”»åƒä»¶æ•°: {len(images)}")
    
    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±å–å¾—ãƒ†ã‚¹ãƒˆ
    print("\nğŸ’¾ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±")
    storage_info = data_service.get_storage_info()
    print(f"ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±: {storage_info}")
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆãƒ†ã‚¹ãƒˆ
    print("\nğŸ”„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆãƒ†ã‚¹ãƒˆ")
    backup_path = data_service.create_backup("test_backup")
    print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‘ã‚¹: {backup_path}")
    
    # æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
    print("\nğŸ§¹ æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ")
    deleted_counts = data_service.manual_cleanup()
    print(f"å‰Šé™¤ä»¶æ•°: {deleted_counts}")
    
    print("âœ… ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    test_data_management()
```

---

## ğŸ“Š å®Ÿè£…å®Œäº†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹å®Ÿè£…å®Œäº†
- [ ] ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜æ©Ÿèƒ½å®Œäº†
- [ ] çµ¦æ°´å±¥æ­´ä¿å­˜æ©Ÿèƒ½å®Œäº†
- [ ] ç”»åƒä¿å­˜æ©Ÿèƒ½å®Œäº†
- [ ] ãƒ‡ãƒ¼ã‚¿å–å¾—æ©Ÿèƒ½å®Œäº†
- [ ] è‡ªå‹•å‰Šé™¤æ©Ÿèƒ½å®Œäº†
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½å®Œäº†
- [ ] APIå®Ÿè£…å®Œäº†
- [ ] ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œå®Œäº†
- [ ] æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå®Œäº†
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ç¢ºèªå®Œäº†

---

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **çµ±åˆãƒ†ã‚¹ãƒˆ**: å…¨ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œç¢ºèª
2. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**: å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æœ€é©åŒ–
3. **ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–**: ã‚°ãƒ©ãƒ•è¡¨ç¤ºæ©Ÿèƒ½ã®å®Ÿè£…
4. **ç›£è¦–æ©Ÿèƒ½**: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡ã®ç›£è¦–

---

**ä½œæˆæ—¥**: 2025å¹´1æœˆ
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0
**ãƒãƒ¼ãƒ **: KEBABS

